{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0e825152",
   "metadata": {},
   "source": [
    "``` Machine Learning ```:\n",
    "It is defined as the ability of a computer system to learn from data and make predictions or decisions based on that data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5288931",
   "metadata": {},
   "source": [
    "``` Use Cases of Machine Learning ```:\n",
    "1. Recommendation systems\n",
    "2. Spam Detection\n",
    "3. Voice Assistant\n",
    "4. Self Driving Cars\n",
    "5. Medical Diagnosis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64137921",
   "metadata": {},
   "source": [
    "```Difference between Machine Learning and Traditional Learning ```:\n",
    "\n",
    "Traditional Learning :\n",
    "1. Gives rules + data ---> Get result\n",
    "2. Manual logic writing\n",
    "\n",
    "Machine Learning :\n",
    "1. Give data + result ---> Get rules(model)\n",
    "2. Learns pattern automatically"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edcd5ffd",
   "metadata": {},
   "source": [
    "``` Difference between Ai , Ml ,Dl ```:\n",
    "\n",
    "1. AI : Artificial Intelligence\n",
    "\n",
    "Ai is the big umbrella - it's the science of making machines smart , just like humans.\n",
    "\n",
    "Examples --> Playing chess like a human\n",
    "\n",
    "--> Talking to Alexa (Ai)\n",
    "\n",
    "--> Driving a car on its own (Ai)\n",
    "\n",
    "2. ML : Machine Learning\n",
    "\n",
    "Ml is a subset of Ai -- This is where machines learn from data and improve over time.\n",
    "\n",
    "Examples --> Youtube recommendations videos\n",
    "\n",
    "--> Spam detection\n",
    "\n",
    "3. DL : Deep Learning\n",
    "\n",
    "It is a subset of Machine learning  -- It uses something called neutral networks , which are inspired by the human brain.\n",
    "\n",
    "Examples --> Face detection , Image classification , Speech recognition"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "585de1df",
   "metadata": {},
   "source": [
    "``` Types of Machine Learning ```:\n",
    "\n",
    "1. Supervised Learning\n",
    "2. Unsupervised Learning\n",
    "3. Reinforcement Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8867ea24",
   "metadata": {},
   "source": [
    "```Steps for making a machine Learning model ```:\n",
    "\n",
    "1. Problem Defination\n",
    "2. data collection\n",
    "3. Exploratory Data Analysis(EDA)\n",
    "4. data preprocessing/ Cleaning\n",
    "5. Feature selection & engineering\n",
    "6. Split the datasets\n",
    "7. Model selection\n",
    "8. Model training\n",
    "9. Model Evaluation\n",
    "10. Hyperparameter tuning\n",
    "11. Model testing/ Validation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5974cf55",
   "metadata": {},
   "source": [
    "``` What is EDA ```:\n",
    "EDA stands for Exploratory Data Analysis -- It's the step where you explore the data to :\n",
    "\n",
    "understand it\n",
    "\n",
    "discover patterns\n",
    "\n",
    "spot anamolies\n",
    "\n",
    "Generate insights\n",
    "\n",
    "And decide what to do next \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0438dfbc",
   "metadata": {},
   "source": [
    "``` EDA steps ```:\n",
    "1. Viewing the data \n",
    "--> Head(), tail(), shape ,info()\n",
    "\n",
    "--> What columns do i have ? What types of Data ?\n",
    "\n",
    "2. Summary Statistics\n",
    "--> mean , median , mode , min , max , quartiles or descirbe()\n",
    "\n",
    "--> helps understand spread and central tendency\n",
    "\n",
    "3. Value counts\n",
    "--> How many unique values in a column ?\n",
    "\n",
    "--> Great for categorical columns\n",
    "\n",
    "4. Missing Value Analysis\n",
    "--> Where are the gaps ? What percent of data is missing ?\n",
    "\n",
    "5. Visualisations\n",
    "--> Histograms --> distribution of values\n",
    "\n",
    "--> Boxplots --> outliers and spread\n",
    "\n",
    "--> Bar plots --> comparisons of categories\n",
    "\n",
    "--> Correlation heatmaps --> linear relationships between numerical features\n",
    "\n",
    "--> Scatter plots --> bivariate relationships \n",
    "\n",
    "6. Target variable exploration \n",
    "--> How does your output ( like 'charges' in your dataset ) relate to other variables ?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2046a230",
   "metadata": {},
   "source": [
    "#### After EDA we do Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01e131f2",
   "metadata": {},
   "source": [
    "1. Handle missing values\n",
    "--> check which columns have missing values(nulls)\n",
    "\n",
    "2. Strategies to handle:\n",
    "--> Drop missing rows/columns (only if very few)\n",
    "\n",
    "--> Impute with :\n",
    "mean / median : for numerical data\n",
    "\n",
    "mode : for categorical data\n",
    "\n",
    "Advanced : Linear regression , KNN , or interpolation ( for future learning)\n",
    "\n",
    "3. Remove Duplicates\n",
    "-- > Detect and drop exact duplicate rows\n",
    "\n",
    "4. Fix data types \n",
    "--> Convert wrong types (e.g. numbers stored as strings , data as text)\n",
    "\n",
    "5. Handle inconsistent categories: \n",
    "--> clean up categorical values like:\n",
    "'Male ' , 'male ', 'MALE' --> should become 'male'\n",
    "\n",
    "'Yes' , 'yes' , 'Y' --> unify to one format\n",
    "\n",
    "6. Detect and Handle Outliers\n",
    "--> Use boxplots , IQR  and z-scores to detect outliers\n",
    "\n",
    "--> Handle by : removing ( if clearly wrong) , capping ( e.g to 95th percentile) \n",
    "\n",
    "7. Fix logic or Domain Errors\n",
    "--> e.g. age = -5 is invalid , or BMI = 150 likely an error\n",
    "\n",
    "--> can replace with mean , median or remove"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d40a10a8",
   "metadata": {},
   "source": [
    "### Data Cleaning\n",
    "\n",
    "EDA tells you what is wrong . Data cleaning fixes it . Cleaning is not glamorous , but it 's 80% of the work in real world projects.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eefc0f1a",
   "metadata": {},
   "source": [
    "### Data Preprocessing\n",
    "\n",
    "1. Encoding categorical variables :\n",
    "convert text labels (like 'male' , 'yes','north') into numbers.\n",
    "\n",
    "there are two ways for it :\n",
    "1. lable encoding (ordinal encoding) : \n",
    "good for ordered categories like 'Low' , 'Medium' , 'High'\n",
    "\n",
    "2. One-hot encoding : good for non-ordered categories like region \n",
    "\n",
    "2. Feature Tranformation : Used to handle skewed data , like right skewed or left skewed\n",
    "\n",
    "3. Feature Scaling ( Normalisation or Standardisation ) : Bring numerical values to the same scale especially useful for distance - based algorithms."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d5fa421",
   "metadata": {},
   "source": [
    "### Feature Engineering\n",
    "\n",
    "Creating new features or transforming existing ones to expose useful patterns that ML models can learn from.\n",
    "\n",
    "why do we need it ? \n",
    "\n",
    "--> Because ml models don't know domain logic -- we have to give them the right signals.\n",
    "\n",
    "Common Feature Engineering Techniques:\n",
    "\n",
    "--> Mathematical combinations\n",
    "\n",
    "--> Target - based Flags\n",
    "\n",
    "--> Binning ( when it helps )\n",
    "\n",
    "--> Time-based Features ( if time exists)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a18175ab",
   "metadata": {},
   "source": [
    "### ``` Feature selection ```:\n",
    "\n",
    "Selecting the most useful features and removing the rest.\n",
    "\n",
    "why it is important ?\n",
    "\n",
    "--> Reduces noise and overfitting\n",
    "\n",
    "--> Speeds up Training\n",
    "\n",
    "--> Improves model accuracy\n",
    "\n",
    "--> Makes model interpretation easier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6558d882",
   "metadata": {},
   "source": [
    "1. Filter methods (Pure Statistics):\n",
    "--> Correlation matrix --> Remove highly correlated features\n",
    "\n",
    "--> Chi-square test --> Categorical VS Categorical\n",
    "\n",
    "--> ANOVA F-test --> Numerical vs Categorical\n",
    "\n",
    "2. Embedded Methods ( Selection built into the model ):\n",
    "--> Lasso Regression --> Shrinks coefficients to 0\n",
    "\n",
    "--> Tree-based models ( Random Forest , XGBoost ) --> Feature importance scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c06cb6b5",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
